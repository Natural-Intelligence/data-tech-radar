# data-tech-radar

[Orchestration](#Orchestration)

## Orchestration

[Apache Airflow](https://github.com/apache/airflow) - Airflow is a platform created by the community to programmatically author, schedule and monitor workflows.

[Apache Liminal](https://github.com/apache/incubator-liminal) - Liminal's goal is to operationalise the machine learning process, allowing data scientists to quickly transition from a successful experiment to an automated pipeline of model training, validation, deployment and inference in production.

[Apache Hop](https://github.com/apache/incubator-hop) - "The Hop Orchestration Platform, or Apache Hop (Incubating), aims to facilitate all aspects of data and metadata orchestration. Hop aims to be the future of data integration. Visual development enables developers to be more productive than they can be through
code."

[Apache DolphinScheduler](https://github.com/apache/dolphinscheduler) - A distributed and easy-to-extend visual workflow scheduler system. Dedicated to solving the complex task dependencies in data processing, making the scheduler system out of the box for data processing.

[Apache Kubeflow](https://github.com/kubeflow/kubeflow) - The Kubeflow project is dedicated to making deployments of machine learning (ML) workflows on Kubernetes simple, portable and scalable. The goal is not to recreate other services, but to provide a straightforward way to deploy best-of-breed open-source systems
for ML to diverse infrastructures.

[mlflow](https://github.com/mlflow/mlflow) - MLflow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, and a central model registry.

[ZenML](https://github.com/zenml-io/zenml) - ZenML is an extensible, open-source MLOps framework to create production-ready machine learning pipelines. It has a simple, flexible syntax, is cloud and tool agnostic, and has interfaces/abstractions that are catered towards ML workflows.

[Metaflow](https://github.com/Netflix/metaflow) - Metaflow helps you design your workflow, run it at scale, and deploy it to production. It versions and tracks all your experiments and data automatically. It allows you to inspect results easily in notebooks.

[Flyte](https://github.com/flyteorg/flyte) - "Flyte makes it easy to create concurrent, scalable, and maintainable workflows for machine learning and data processing.
Flyte is used in production at Lyft, Spotify, Freenome and others."

[ClearML](https://github.com/allegroai/clearml) - ClearML is the only open source tool to manage all your MLOps in a unified and robust platform providing collaborative experiment management, powerful orchestration, easy-to-build data stores, and one-click model deployment. ClearML is the foundation for your data science team.

[Pachyderm](https://github.com/pachyderm/pachyderm/) - Pachyderm provides the data layer that allows machine learning teams to productionize and scale their machine learning lifecycle. With Pachydermâ€™s industry leading data versioning, pipelines and lineage teams gain data driven automation, petabyte scalability and end-to-end reproducibility. Teams using Pachyderm get their ML projects to market faster, lower data processing and storage costs, and can more easily meet regulatory compliance requirements

[Prefect](https://github.com/PrefectHQ/prefect) - The prefect Python library includes everything you need to design, build, test, and run powerful data applications. Instantly upgrade your existing code with workflow best practices, and use the Prefect UI to orchestrate and monitor everything.

[Ploomber](https://github.com/ploomber/ploomber) - Ploomber is a framework to build collaborative and modular pipelines; it integrates with Jupyter but you can use it with any other editor.
Ploomber eliminates the notebook refactoring problem: data teams prototype their work in Jupyter notebooks and then refactor the code for deployment.

[Amazon SageMaker](https://aws.amazon.com/sagemaker/) - Amazon SageMaker helps data scientists and developers to prepare, build, train, and deploy high-quality machine learning (ML) models quickly by bringing together a broad set of capabilities purpose-built for ML.

[Google Cloud Vertex AI](https://cloud.google.com/vertex-ai/) - Vertex AI brings together the Google Cloud services for building ML under one, unified UI and API. In Vertex AI, you can now easily train and compare models using AutoML or custom code training and all your models are stored in one central model repository. These models can now be deployed to the same endpoints on Vertex AI.
